# ✊✋✌ Rock Paper Scissors Image Classification

![Rock Paper Scissors](https://github.com/user-attachments/assets/7dfcf0ee-3521-45dd-9d96-ce6b26c752ac)

## 📖 Overview
This project implements an **image classification model** to recognize hand gestures for **Rock, Paper, and Scissors** using **Machine Learning**. The model is trained on a dataset containing images of different hand gestures and classifies them into one of the three categories.

## 📊 Dataset
The dataset consists of images representing:
- ✊ **Rock**
- ✋ **Paper**
- ✌ **Scissors**

The dataset is split into **80% training** and **20% testing** to optimize the model’s performance.

## 🚀 Features
- **Image Preprocessing**
- **Model Training**
- **Evaluation**
- **Visualization**

## 🔧 Technologies Used
- Python 🐍
- TensorFlow / Keras 🔥
- OpenCV 📸
- Matplotlib 📊
- NumPy & Pandas 🏗

## 📌 Project Structure
```
📂 Rock-Paper-Scissors-Classification
 ┣ 📁 data              # Image dataset
 ┣ 📁 notebooks         # Jupyter Notebooks
 ┣ 📁 models           # Trained ML models
 ┣ 📜 README.md        # Project documentation
 ┣ 📜 requirements.txt  # Dependencies
```

## 📈 Model Performance
The classification model achieved **high accuracy** after training. Below is an example of the model’s predictions:

| **Input Image** | **Predicted Class** |
|----------------|---------------------|
| ![paper](https://github.com/user-attachments/assets/2fb88642-eb68-4a9d-aabe-56990881b5b6) | ✋ Paper |



## 🔍 How to Use
Clone this repository:
   ```bash
   git clone https://github.com/yourusername/rock-paper-scissors-classification.git
   
   ```

---
✨ **Star this repository** if you found it useful!
